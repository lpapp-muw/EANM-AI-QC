{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143e7b20",
   "metadata": {},
   "source": [
    "# NIfTI PET±mask demo (synthetic mockups)\n",
    "\n",
    "The NIfTI volumes are randomly generated mockups. Performance metrics are not clinically meaningful.\n",
    "\n",
    "This notebook focuses on:\n",
    "- verifying the PET±mask loader path\n",
    "- running QCNN training\n",
    "- visualizing test confusion matrices and ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25311dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "REPO = Path().resolve()\n",
    "assert (REPO/'qnm_qai.py').exists(), \"Run Jupyter from the repository root (folder containing qnm_qai.py)\"\n",
    "print(\"Repo root:\", REPO)\n",
    "print(\"Python:\", sys.executable)\n",
    "\n",
    "# Best-effort: ensure Results exists\n",
    "(Path(\"Results\")).mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_matplotlib()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "def _safe_div(num, den):\n",
    "    return float(num) / float(den) if float(den) != 0.0 else float(\"nan\")\n",
    "\n",
    "def cm_metrics_from_preds(y_true, prob1, threshold=0.5):\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    prob1 = np.asarray(prob1, dtype=float)\n",
    "    y_pred = (prob1 >= float(threshold)).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    sens = _safe_div(tp, tp + fn)\n",
    "    spec = _safe_div(tn, tn + fp)\n",
    "    ppv  = _safe_div(tp, tp + fp)\n",
    "    npv  = _safe_div(tn, tn + fn)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # AUC is undefined if only one class is present\n",
    "    auc = float(\"nan\")\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        auc = roc_auc_score(y_true, prob1)\n",
    "\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
    "        \"sensitivity\": sens,\n",
    "        \"specificity\": spec,\n",
    "        \"ppv\": ppv,\n",
    "        \"npv\": npv,\n",
    "        \"accuracy\": float(acc),\n",
    "        \"balanced_accuracy\": float(bal),\n",
    "        \"auc\": float(auc),\n",
    "    }, cm\n",
    "\n",
    "def show_confusion_matrix(cm, title=\"Confusion matrix\", labels=(\"0\", \"1\")):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    cm = np.asarray(cm, dtype=int)\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 3.6))\n",
    "    im = ax.imshow(cm)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0, 1], labels=labels)\n",
    "    ax.set_yticks([0, 1], labels=labels)\n",
    "\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_roc_curve(y_true, prob1, title=\"ROC curve\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        print(\"ROC: only one class present in y_true; skipping.\")\n",
    "        return\n",
    "    RocCurveDisplay.from_predictions(y_true, prob1)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def ensure_matplotlib():\n",
    "    try:\n",
    "        import matplotlib.pyplot as _plt  # noqa: F401\n",
    "    except Exception:\n",
    "        # Notebook-safe install\n",
    "        import sys\n",
    "        !{sys.executable} -m pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508f144",
   "metadata": {},
   "source": [
    "## Generate synthetic NIfTI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/make_synthetic_nifti.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3e257",
   "metadata": {},
   "source": [
    "## Train + evaluate QCNNs (no SHAP/LIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python qnm_qai.py run   --input demo_data/nifti_masked   --input-type nifti   --methods pl_qcnn_alt,pl_qcnn_muw   --results-dir Results   --test-size 0.30   --max-samples-per-method 40   --qcnn-epochs 10   --qcnn-lr 0.02   --qcnn-batch-size 4   --qcnn-init-scale 0.1   --seed 0   --no-explain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5071561f",
   "metadata": {},
   "source": [
    "## Summary metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe653b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "summary = Path(\"Results\")/\"nifti_masked__results.csv\"\n",
    "pd.read_csv(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6c573",
   "metadata": {},
   "source": [
    "## Per-method test confusion matrices + ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base = Path(\"Results\")/\"nifti_masked\"\n",
    "for method in [\"pl_qcnn_alt\",\"pl_qcnn_muw\"]:\n",
    "    pred_path = base/method/\"predictions\"/\"test.csv\"\n",
    "    print(\"\\nMETHOD:\", method)\n",
    "    dfp = pd.read_csv(pred_path)\n",
    "    display(dfp.head(10))\n",
    "\n",
    "    if \"true_label\" not in dfp.columns:\n",
    "        print(\"No true_label column; cannot compute confusion matrix.\")\n",
    "        continue\n",
    "\n",
    "    y = dfp[\"true_label\"].astype(int).to_numpy()\n",
    "    prob1 = dfp[\"prob_1\"].astype(float).to_numpy()\n",
    "\n",
    "    metrics, cm = cm_metrics_from_preds(y, prob1, threshold=0.5)\n",
    "    display(pd.DataFrame([metrics]))\n",
    "    show_confusion_matrix(cm, title=f\"nifti_masked / {method} — test CM (thr=0.5)\")\n",
    "    show_roc_curve(y, prob1, title=f\"nifti_masked / {method} — test ROC\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
