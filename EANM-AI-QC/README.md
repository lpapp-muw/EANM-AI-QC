# EANM-AI-QC

Unified reference implementation for:
- **Tabular quantum ML** (quantum-kernel SVM)
- **3D NIfTI PET quantum CNNs** (PET ± ROI mask pairs)

This code runs quantum circuits on a classical simulator by default (PennyLane `default.qubit`).
It prints explicit evaluation diagnostics (train/test confusion matrices and per-test-case predictions)
to prevent misinterpretation of metrics vs inference-only predictions.

## Quick start (Ubuntu)

```bash
sudo apt update
sudo apt install -y python3 python3-venv python3-pip
```

```bash
cd ~/EANM-AI-QC
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install --upgrade pip
python3 -m pip install -r requirements.txt
```

## Generate synthetic demo inputs

```bash
python3 examples/make_synthetic_tabular.py
python3 examples/make_synthetic_nifti.py
```

## Run all examples

```bash
bash examples/run_all_examples.sh
```

Outputs:
- models saved under `models/`
- prediction CSVs saved under `outputs/`

## Tabular input requirements

- CSV/TSV with a label column named **`label`** (default).
- If your label column has another name, pass `--label-col <name>` during training.
- Inference CSVs can omit the label column.

## NIfTI input requirements (PET ± mask)

Supported layouts:

### A) Explicit split

```
dataset_root/
  Train/
    case001_0_PET.nii.gz
    case001_0_mask.nii.gz   (optional)
  Test/
    ...
```

### B) Flat layout (internal split)

```
dataset_root/
  case001_0_PET.nii.gz
  case001_0_mask.nii.gz
  ...
```

### Mask semantics

- `mask > 0` means voxel belongs to VOI
- `mask == 0` means voxel is excluded
- applied as: `PET := where(mask>0, PET, 0)`

If no mask exists (or masks are disabled via `--mask-pattern NONE`) the full PET volume is used.

### Resolution handling

- no forced image resolution
- flatten volume and pad to `2^n` for amplitude encoding
- optional resampling via `--target-shape Z Y X` (requires SciPy)

## Output CSV interpretation

Prediction CSV columns:
- `id`: sample id (row index for tabular; case id for NIfTI)
- `prob_1`: predicted probability for class `labelmap.classes[1]`
- `pred_01`: thresholded prediction (0/1 at 0.5)
- `pred_label`: predicted label token in original label namespace

## Evaluation prints during training

The `train` command prints:
- TRAIN and TEST confusion matrices (clearly labeled)
- sensitivity, specificity, PPV, NPV
- per-test-case (id, prob_1, pred, true)

This is the correct way to connect aggregate metrics and individual predictions.


## Included real tabular dataset (FDB/LDB)

This repo snapshot includes:
- `demo_data/tabular/raw/FDB.csv`
- `demo_data/tabular/raw/LDB.csv`
- `demo_data/tabular/real_train.csv`
- `demo_data/tabular/real_infer.csv`
- `demo_data/tabular/real_feature_map.csv`

`examples/run_all_examples.sh` trains the tabular model on `real_train.csv`.

## Notes on included example data

### Real tabular dataset (radiomics; PSMA-11 PET)

The repository includes a **real tabular example dataset** containing **anonymized PSMA-11 PET radiomic features** extracted from **primary prostate lesions**, with an associated **binary label** intended to predict **Gleason risk**.

This real tabular data example is sourced from the OSF repository:
- https://osf.io/3nkx8/files/osfstorage

In this codebase, the tabular features are used to demonstrate the end-to-end workflow:
- load CSV features + label
- train a quantum-kernel model (simulator backend)
- print train/test diagnostics (confusion matrices, sensitivity/specificity, PPV/NPV)
- run inference and save prediction CSV outputs

### NIfTI datasets (synthetic mockups)

The NIfTI volumes generated by the example scripts are **randomly-generated mockups**. They exist to validate that:
- the PET±mask loader works,
- the amplitude-encoding and QCNN pipelines run,
- model saving/loading and inference work end-to-end.

Because these NIfTI volumes are synthetic, the prediction results of the QCNN models (**muw** or **alt**) are **not** representative of the methods’ real capabilities. Use your own NIfTI datasets (ideally with clinically meaningful VOIs and labels) for any performance assessment.

### Practical recommendation for simulator feasibility

Amplitude encoding requires vectors of length `2^n` (padding is applied automatically), and QCNN circuit width is driven by `n_qubits`.

To avoid generating overly complex circuits in a simulator environment:
- prefer **small NIfTI inputs**, e.g. VOIs around lesions rather than whole-body volumes,
- consider resampling to a modest target shape (if appropriate),
- start with small `epochs` and only scale up after the pipeline is stable.

## QCNN variants: muw vs alt

Both QCNN options share the same NIfTI loader and preprocessing, but differ in circuit design.

### muw (MUW-like)

Core characteristics:
- amplitude embedding on all qubits
- repeated convolution + pooling blocks (pairwise IsingXX/YY/ZZ entanglers + controlled pooling)
- a final **ArbitraryUnitary** block on the remaining pooled qubits
- output is the probability of measuring `|1⟩` on a designated qubit

Pros:
- high expressivity at the end due to the ArbitraryUnitary block
- structurally close to the MUW-style QCNN pattern that motivated this code path

Cons:
- optimization can be brittle on small datasets or noisy targets (flat gradients / poor conditioning)
- the ArbitraryUnitary parameterization can make training less stable and slower

### alt (alternative)

Core characteristics:
- amplitude embedding on all qubits
- convolution + pooling blocks similar in spirit
- a final **StronglyEntanglingLayers** block as the trainable “dense” head
- output is the probability of measuring `|1⟩` on a designated qubit

Pros:
- usually easier to optimize than a full ArbitraryUnitary head
- tends to be more stable for quick demonstrations and debugging

Cons:
- potentially less expressive than an ArbitraryUnitary head in the final pooled space
- still subject to simulator scaling limits as `n_qubits` grows
